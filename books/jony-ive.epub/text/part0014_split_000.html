<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Jony Ive</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" type="text/css" rel="stylesheet"/>
<link href="../page_styles.css" type="text/css" rel="stylesheet"/>
</head>
  <body id="x9781101614846_EPUB" class="calibre">
<div style="height:0pt" id="x9781101614846_EPUB"></div><div class="Basic-Text-Frame">
			<h1 class="x03-Chapter-Number" id="calibre_pb_0"><span class="gray"><a id="pageMap_211" class="calibre2"></a>CHAPTER 10</span></h1>
			<h1 class="x03-Chapter-Title">The iPhone</h1>
			<p class="x03-Chapter-Epigraph">When we are at these early stages in design . . . often we’ll talk about the story for the product—we’re talking about perception. We’re talking about how you feel about the product, not in a physical sense, but in a perceptual sense.</p>
			<p class="x03-Chapter-Epigraph-Source">—JONY IVE</p>
			<p class="x03-CO-Body-Text">One morning in late 2003, just before the launch of the iPod mini, Jony and his team gathered for a biweekly brainstorming meeting. As usual, the team assembled around the studio’s kitchen table. One of the industrial designers, Duncan Kerr, did a show-and-tell. Kerr, who joined Apple’s design team in 1999 after having spent a few years working at IDEO, had a lot of engineering experience, and he loved to tinker with new technology.</p>
			<p class="x04-Body-Text">Kerr had been working with Apple’s input engineering group, which was exploring alternative inputs for the Mac, with the hope of doing away with the keyboard and mouse, the mainstay of computing for more than three decades. When Kerr told the group about what he’d learned, his words were greeted by some stunned expressions.</p>
			<p class="x04-Body-Text">“It was amazing,” said Doug Satzger, shaking his head in disbelief. “It was a really amazing brainstorm.”</p>
			<p class="x04-Body-Text">Around the table was the core IDg: Jony, Richard Howarth, Chris Stringer, Eugene Whang, Danny Coster, Danny De Iuliis, Rico Zorkendorfer, Shin Nishibori, Bart Andre, and Satzger.</p>
			<p class="x04-Body-Text"><a id="pageMap_212"></a>“I remember Duncan showing us how, with multi-touch, you could do different things with two fingers and with three fingers,” recalled Satzger. “He showed us on-screen rotating and zooming—and I was really surprised that we could do that stuff.”</p>
			<p class="x04-Body-Text">That morning was the first time the team had even heard of multi-touch. Today it doesn’t seem exceptional, but back then, touch interfaces were pretty primitive. Most touch devices, such as Palm Pilots and Windows tablets, used a pen or stylus. Screens that were sensitive to fingers, not pens, like ATM screens, were restricted to single presses. There was no pinching or zooming, no swiping up and down or left and right.</p>
			<p class="x04-Body-Text">Kerr explained to his colleagues that the new technology would allow people to use two or three fingers instead of just one, and that it would afford much more sophisticated interfaces than simple single-finger button presses.</p>
			<p class="x04-Body-Text">Excited by Kerr’s explanation of what a sophisticated touch interface could do, the team members started to brainstorm the kinds of hardware they might build with it. The most obvious idea was a touch-screen Mac. Instead of a keyboard and mouse, users could tap on the screen of the computer to control it. One of the designers suggested a touch-screen controller that functioned as an alternative to a keyboard and mouse, a sort of virtual keyboard with soft keys.</p>
			<p class="x04-Body-Text">As Satzger remembered, “We asked, ‘How do we take a tablet, which has been around for a while, and do something more with it?’ Touch is one thing, but multi-touch was new. You could swipe to turn a page, as opposed to finding a button on the screen that would allow you turn the page. Instead of trying to find a button to make operations, we could turn a page just like a newspaper. I was really surprised you could do this stuff.”</p>
			<p class="x04-Body-Text">Jony in particular had always had a deep appreciation for the tactile nature of computing; he had put handles on several of his early machines specifically to encourage touching. But here was an opportunity to make <a id="pageMap_213"></a>the ultimate tactile device. No more keyboard, mouse, pen or even a click wheel—the user would touch the actual interface with his or her fingers. What could be more intimate?</p>
			<p class="x04-Body-Text">The input engineering team had built a giant experimental system to test multi-touch. It was a big capacitive display about the size of a Ping-Pong table, with a projector suspended above it. The projector shone the Mac’s operating system onto the array, which was a mass of wires.</p>
			<p class="x04-Body-Text">“This is going to change everything,” Jony told the design team after he saw it.<a id="SuperscriptNumber303"></a><sup class="endnote"><a href="part0054.html#EndnoteNumber303" class="calibre2">1</a></sup> Jony wanted to show the system to Steve Jobs, but he was afraid his boss would pour cold water on it because it was still raw and unpolished. Jony reasoned that he had to show the work in progress to Jobs in private, with no one else around. “Because Steve is so quick to give an opinion, I didn’t show him stuff in front of other people,” Jony said. “He might say ‘This is shit,’ and snuff the idea. I feel that ideas are very fragile, so you have to be tender when they are in development. I realized that if he pissed on this, it would be so sad because I know it was so important.”<a id="SuperscriptNumber304"></a><sup class="endnote"><a href="part0054.html#EndnoteNumber304" class="calibre2">2</a></sup></p>
			<p class="x04-Body-Text">Jony followed his instincts and showed Jobs the system in private. The gambit worked, and Jobs loved the idea. “This is the future,” said Jobs.<a id="SuperscriptNumber305"></a><sup class="endnote"><a href="part0054.html#EndnoteNumber305" class="calibre2">3</a></sup></p>
			<p class="x04-Body-Text">With Jobs’s seal of approval, Jony directed Imran Chaudhri and Bas Ording, two of Apple’s most talented software engineers, to shrink the massive capacitive array into a working tablet prototype. Within a week, they came back with a twelve-inch MacBook display hooked to a big tower Power Mac, which provided the computing power to interpret the finger gestures.</p>
			<p class="x04-Body-Text">They showed Jony and the designers a demonstration with Google Maps. After bringing up Apple’s Cupertino HQ, one of them spread his fingers apart on the screen, zooming in on the campus. The designers were astonished. “We could zoom in and zoom out with touch gestures onto the Apple campus!” said Satzger.</p>
			<p class="x04-Body-Text"><a id="pageMap_214"></a>Building a finger-controlled tablet looked like a real possibility. It wouldn’t happen overnight and, thanks to market forces, another revolutionary Apple product would emerge from the pipeline first.</p>
			</div>
	</body></html>
